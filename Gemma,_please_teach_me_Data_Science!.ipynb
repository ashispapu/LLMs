{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 64148,
          "databundleVersionId": 7669720,
          "sourceType": "competition"
        },
        {
          "sourceId": 11372,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 5388
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Gemma, please teach me Data Science!",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashispapu/LLMs/blob/main/Gemma%2C_please_teach_me_Data_Science!.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1>Gemma, please teach me Data Science!</h1></center>\n",
        "\n",
        "<center><img src=\"https://res.infoq.com/news/2024/02/google-gemma-open-model/en/headerimage/generatedHeaderImage-1708977571481.jpg\" width=\"400\"></center>\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "This notebook aims to show how we can, with a very simple approach, to exploit the rich information that Gemma already acquired through training and answer questions about Data Science.\n",
        "\n",
        "**Let's go**!\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "n4KZKqmnEizW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install resources\n",
        "\n",
        "We start with few logistic steps, installing the needed resources and preparing our tools.\n",
        "\n",
        "We will use Gemma through Keras interface.\n",
        "\n",
        "## Install Keras NLP and Keras"
      ],
      "metadata": {
        "id": "1Y3dPF0oEizZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U keras>=3"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:28:47.569022Z",
          "iopub.execute_input": "2024-03-31T11:28:47.569291Z",
          "iopub.status.idle": "2024-03-31T11:29:17.65124Z",
          "shell.execute_reply.started": "2024-03-31T11:28:47.569267Z",
          "shell.execute_reply": "2024-03-31T11:29:17.650235Z"
        },
        "trusted": true,
        "id": "pK8DOaVQEizb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "5896ZWiREizd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:29:17.656369Z",
          "iopub.execute_input": "2024-03-31T11:29:17.65672Z",
          "iopub.status.idle": "2024-03-31T11:29:30.373849Z",
          "shell.execute_reply.started": "2024-03-31T11:29:17.656682Z",
          "shell.execute_reply": "2024-03-31T11:29:30.372864Z"
        },
        "trusted": true,
        "id": "1wKXn4YJEize"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup some environment variables"
      ],
      "metadata": {
        "id": "QwCnZwQcEizf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the desired backend for Keras. Options: \"jax\", \"tensorflow\", or \"torch\".\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Adjust as needed.\n",
        "\n",
        "# Specific to the JAX backend, this setting helps avoid memory fragmentation, ensuring more efficient resource use.\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:29:30.376075Z",
          "iopub.execute_input": "2024-03-31T11:29:30.377069Z",
          "iopub.status.idle": "2024-03-31T11:29:30.382068Z",
          "shell.execute_reply.started": "2024-03-31T11:29:30.377033Z",
          "shell.execute_reply": "2024-03-31T11:29:30.380996Z"
        },
        "trusted": true,
        "id": "YGmJRZKEEizg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility for formatting the output"
      ],
      "metadata": {
        "id": "BGseBKMXEizh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorize_text(text):\n",
        "    for word, color in zip([\"Reasoning\", \"Question\", \"Answer\"], [\"blue\", \"red\", \"green\"]):\n",
        "        text = text.replace(f\"{word}:\", f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
        "    return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:29:30.383453Z",
          "iopub.execute_input": "2024-03-31T11:29:30.383856Z",
          "iopub.status.idle": "2024-03-31T11:29:30.46666Z",
          "shell.execute_reply.started": "2024-03-31T11:29:30.383825Z",
          "shell.execute_reply": "2024-03-31T11:29:30.465747Z"
        },
        "trusted": true,
        "id": "oPqKWFY7Eizj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Gemma Causal LM\n",
        "\n",
        "We will try for this application `gemma_instruct_2b_en`."
      ],
      "metadata": {
        "id": "iCgG8EP1Eizj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:29:30.46787Z",
          "iopub.execute_input": "2024-03-31T11:29:30.46862Z",
          "iopub.status.idle": "2024-03-31T11:30:36.331326Z",
          "shell.execute_reply.started": "2024-03-31T11:29:30.468571Z",
          "shell.execute_reply": "2024-03-31T11:30:36.330346Z"
        },
        "trusted": true,
        "id": "6xlnySpJEizk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the Q&A class\n",
        "\n",
        "\n",
        "We will setup a class for querying directly the Gemma model about Data Science."
      ],
      "metadata": {
        "id": "z_05LsJpEizl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GemmaQA:\n",
        "    def __init__(self, max_length=512):\n",
        "        self.max_length = max_length\n",
        "        self.prompt = \"\"\"\n",
        "            You are an AI assistant designed to answer questions about Data Science.\n",
        "            Reasoning: If the question is not related to Data Science, simply state politely this.\n",
        "            If it is a complex question, think step by step. If needed, include your reasoning process.\n",
        "            Question: {question}\n",
        "            Answer:\n",
        "        \"\"\"\n",
        "        self.gemma_lm = gemma_lm\n",
        "\n",
        "    def query(self, question):\n",
        "        response = self.gemma_lm.generate(\n",
        "            self.prompt.format(\n",
        "                question=question),\n",
        "            max_length=self.max_length)\n",
        "        display(Markdown(colorize_text(response)))\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:30:36.333565Z",
          "iopub.execute_input": "2024-03-31T11:30:36.33386Z",
          "iopub.status.idle": "2024-03-31T11:30:36.340103Z",
          "shell.execute_reply.started": "2024-03-31T11:30:36.333836Z",
          "shell.execute_reply": "2024-03-31T11:30:36.339221Z"
        },
        "trusted": true,
        "id": "Ipk-yPf2Eizm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's initialize the class.\n",
        "\n",
        "If we are not giving any parameters, the default initialization with `max_length` = 512 will be used.\n",
        "\n",
        "Let's use instead initialization with `max_length` = 256."
      ],
      "metadata": {
        "id": "XG4f0iQdEizn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda = GemmaQA(max_length=256)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:31:23.881314Z",
          "iopub.execute_input": "2024-03-31T11:31:23.881709Z",
          "iopub.status.idle": "2024-03-31T11:31:23.885943Z",
          "shell.execute_reply.started": "2024-03-31T11:31:23.881677Z",
          "shell.execute_reply": "2024-03-31T11:31:23.885009Z"
        },
        "trusted": true,
        "id": "NclrDnQ9Eizo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model - ask few questions on Data Science"
      ],
      "metadata": {
        "id": "-gRPlX2sEizp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1: Ask about sklearn\n",
        "\n",
        "Let's test first with a simple question about `sklearn`."
      ],
      "metadata": {
        "id": "cTlw6xRTEizp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda.query(\"Please teach me how to do a train test split using sklearn\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:31:26.88491Z",
          "iopub.execute_input": "2024-03-31T11:31:26.885267Z",
          "iopub.status.idle": "2024-03-31T11:31:50.446468Z",
          "shell.execute_reply.started": "2024-03-31T11:31:26.885238Z",
          "shell.execute_reply": "2024-03-31T11:31:50.445545Z"
        },
        "trusted": true,
        "id": "LHMtsCWREizq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doesn't look fine, isn't it? Let's get back to the default settings."
      ],
      "metadata": {
        "id": "p-gqP_w6Eizq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda = GemmaQA()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:33:08.738056Z",
          "iopub.execute_input": "2024-03-31T11:33:08.738844Z",
          "iopub.status.idle": "2024-03-31T11:33:08.743017Z",
          "shell.execute_reply.started": "2024-03-31T11:33:08.738813Z",
          "shell.execute_reply": "2024-03-31T11:33:08.742061Z"
        },
        "trusted": true,
        "id": "EhXgD3TZEizr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda.query(\"Please teach me how to do a train test split using sklearn\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:33:19.162665Z",
          "iopub.execute_input": "2024-03-31T11:33:19.163038Z",
          "iopub.status.idle": "2024-03-31T11:33:47.536752Z",
          "shell.execute_reply.started": "2024-03-31T11:33:19.163009Z",
          "shell.execute_reply": "2024-03-31T11:33:47.535809Z"
        },
        "trusted": true,
        "id": "kVCdPqMSEizr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Ask about bias and variance\n",
        "\n",
        "Now, let's ask something different. Will ask Gemma about bias and variance."
      ],
      "metadata": {
        "id": "vEzik4igEizs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda.query(\"Please explain to me the concepts of bias and variance\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:33:47.538321Z",
          "iopub.execute_input": "2024-03-31T11:33:47.538579Z",
          "iopub.status.idle": "2024-03-31T11:33:54.917572Z",
          "shell.execute_reply.started": "2024-03-31T11:33:47.538557Z",
          "shell.execute_reply": "2024-03-31T11:33:54.916647Z"
        },
        "trusted": true,
        "id": "dBBRfmIoEizs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3: Ask about Dropout\n",
        "\n",
        "Let's ask something from Deep Learning, more specific, about Dropout layers."
      ],
      "metadata": {
        "id": "CdedDZPDEizt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda.query(\"What is the role of Dropout layer added to a Deep Learning architecture?\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:36:40.327976Z",
          "iopub.execute_input": "2024-03-31T11:36:40.328922Z",
          "iopub.status.idle": "2024-03-31T11:36:48.780613Z",
          "shell.execute_reply.started": "2024-03-31T11:36:40.328889Z",
          "shell.execute_reply": "2024-03-31T11:36:48.779659Z"
        },
        "trusted": true,
        "id": "FUbZpCPKEizu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4: Ask about model calibration\n",
        "\n",
        "Now, let's ask a more advanced question."
      ],
      "metadata": {
        "id": "MCyHCVkyEizu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_qanda.query(\"Could you explain, in the context of Data Science, what is model calibration?\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T11:36:48.782505Z",
          "iopub.execute_input": "2024-03-31T11:36:48.78314Z",
          "iopub.status.idle": "2024-03-31T11:36:58.334993Z",
          "shell.execute_reply.started": "2024-03-31T11:36:48.783105Z",
          "shell.execute_reply": "2024-03-31T11:36:58.334068Z"
        },
        "trusted": true,
        "id": "AkEVCdlSEizv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "In this first attempt to create a simple tool to answer to our questions about Data Science, we tested the capability of Gemma model to answer to few questions related to Data Science directly, without prompting it with some special documentation.\n",
        "\n",
        "The results were quite good, actually unexpected good, considering that we were just using a system prompt adapted to the task. Maybe the last question could have been answered better, but, well, how many of us have actually used Platt calibrations curves or other method for model calibration? Btw., here is a good article describing the concepts related to model calibration: [A Comprehensive Guide on Model Calibration: What, When, and How](https://towardsdatascience.com/a-comprehensive-guide-on-model-calibration-part-1-of-4-73466eb5e09a)\n",
        "\n",
        "The results shows that Gemma was trained well with data about Data Science domain. To further extend and maybe take it up-to-date, we can ingest recent information about Data Science in a vector database and create a Retrieval Augmented Generation system.\n"
      ],
      "metadata": {
        "id": "78p_pbneEizv"
      }
    }
  ]
}